---
title: Inferencing Transformers in Real-Time
date: 2025-05-13
description: A journal on writing CUDA kernels from scratch to run GPT-2 at almost 70 tokens per second on an A40 GPU, exploring optimization techniques from tensor cores to flash attention.
tags: ['CUDA', 'transformers', 'GPU', 'optimization', 'inference', 'tensor-cores', 'flash-attention']
author: Tianhao Chen, Raghav Tirumale, and Vasunandan Dar
readTime: 20 min read
featured: true
draft: false
---

**Read the full article:** [Inferencing Transformers in Real-Time](https://open.substack.com/pub/tianhaochen/p/inferencing-transformers-in-real?r=2qo6u2&utm_campaign=post&utm_medium=web&showWelcomeOnShare=false)

Co-authored with Tianhao Chen and Vasunandan Dar.
